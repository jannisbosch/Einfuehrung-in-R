---
title: "Datenauswertung in R"
author: "Dr. Jannis Bosch"
format: 
  revealjs:
    theme: moon
execute:
  echo: true
embed-resources: true
---

## Setup

- Bitte erstellt wieder ein R Projekt und öffnet es



- Erstellt ein R-Skript für den heutigen Workshop

## Daten herunterladen

[Hier klicken um den Datensatz runterzuladen](dateien/experiment_data.rds){target="_blank"}

## Daten einlesen

```{r}
# Lest zunächst den Datensatz ein
mydata <- readRDS(file.path("dateien", "experiment_data.rds"))

# Schaut euch dann die Struktur des Datensatzes in RStudio an
```

# Wiederholung - Skalen bilden

## Items für die Skalen definieren

```{r}
# Im Datensatz sind Items aus acht verschiedenen Skalen
# Erstellt nun zunächst für jede Skala einen Vektor mit den Item-Namen im Datensatz
sc1_items <- c("sc1_1", "sc1_2_rev", "sc1_3", "sc1_4_rev") # self-concept (pre-test)
sc2_items <- c("sc2_1", "sc2_2_rev", "sc2_3", "sc2_4_rev") # self-concept (post-test)
int1_items <- c("int1_1", "int1_2", "int1_3", "int1_4") # interest (pre-test)
int2_items <- c("int2_1", "int2_2", "int2_3", "int2_4") # interest (post-test)
sco_ability_items <- c("SCO1", "SCO2", "SCO3", "SCO4", "SCO5_rev", "SCO6") # social comparison orientation ability
sco_opinion_items <- c("SCO7", "SCO8", "SCO9", "SCO10", "SCO11_rev") # social comparison orientation opinion
identification_items <- c("Ident1", "Ident2", "Ident3", "Ident4") # university identification
enjoyment_items <- c("End1", "End2_rev", "End3") # enjoyment of the task

# Diese Variablen können wir später zur Berechnung der Skalenmittelwerte nutzen
```

## Cronbach's Alpha

```{r}
# psych-Bibliothek laden
library(psych)

alpha(mydata[,sc1_items]) # entspricht: alpha(mydata[,c("sc1_1", "sc1_2_rev", "sc1_3", "sc1_4_rev")])

# Schaut euch mal das Cronbach's Alpha der SCO Skalen an
# Findet ihr potentiell unpassende Items?
```

## Cronbach's Alpha - SCO ability

```{r}
alpha(mydata[,sco_ability_items])
# Item 1 passt nicht perfekt
```

## Cronbach's Alpha - SCO ability
```{r}
alpha(mydata[,sco_opinion_items])
# Item 11 passt überhaupt nicht (Alpha geht hoch, Trennschärfe von .07)
```

## Skalenmittelwerte berechnen

```{r}
# Wie beim letzten mal erstellen wir jetzt neue Spalten für die 
# Skalenmittelwerte mit der rowMeans()-Funktion
mydata[,"sc1_mean"] <- rowMeans(mydata[,sc1_items], na.rm = T)
mydata[,"sc2_mean"] <- rowMeans(mydata[,sc2_items], na.rm = T)
mydata[,"int1_mean"] <- rowMeans(mydata[,int1_items], na.rm = T)
mydata[,"int2_mean"] <- rowMeans(mydata[,int2_items], na.rm = T)
mydata[,"sco_ability_mean"] <- rowMeans(mydata[,sco_ability_items], na.rm = T)
mydata[,"sco_opinion_mean"] <- rowMeans(mydata[,sco_opinion_items], na.rm = T)
mydata[,"identification_mean"] <- rowMeans(mydata[,identification_items], na.rm = T)
mydata[,"enjoyment_mean"] <- rowMeans(mydata[,enjoyment_items], na.rm = T)
```

# Exkurs: dplyr, tidyr und das tidyverse

## Das tidyverse

- Das tidyverse ist eine Sammlung von Bibliotheken zur Datenanalyse

- Es beinhaltet verschiedene Bibliotheken und Funktionen, die die Datenaufbereitung erleichtern, Tools zur Erstellung von Graphiken (ggplot) und vieles mehr

- Mehr Informationen unter <https://www.tidyverse.org/>

## R Cheat Sheets

- Cheat Sheets sind eine graphische Aufbereitung verschiedener Funktionen von Bibliotheken

- [dplyr Cheat Sheet](https://nyu-cdsc.github.io/learningr/assets/data-transformation.pdf){target="_blank"}

- [tidyr Cheat Sheet](https://raw.githubusercontent.com/rstudio/cheatsheets/main/tidyr.pdf){target="_blank"}

## tidyverse installieren

</br>
```{r}
#| eval: false
# Die Bibliothek installieren
install.packages("tidyverse")
```
</br>
```{r}
# Und die Bibliothek laden
library(tidyverse)
```

# Daten aufbereiten

## Datensatz aufräumen

```{r}
# Zur besseren Übersicht bietet es sich nach Berechnung der Skalenmittelwerte 
# an einen neuen Datensatz zu erstellen, der die Einzelitems nicht beinhaltet 
mydata_scales <- select(mydata, !c(all_of(c(int1_items, int2_items, sc1_items, sc2_items, sco_ability_items, sco_opinion_items, enjoyment_items, identification_items)), "sc1_2", "sc1_4", "sc2_2", "sc2_4", "SCO5", "SCO11", "End2"))
```

## Datensatz aufräumen

```{r}
# Das geht auch mit der pipe
mydata_scales <- mydata |>
  select(!c(all_of(c(int1_items, int2_items, sc1_items, sc2_items, sco_ability_items, sco_opinion_items, enjoyment_items, identification_items)), "sc1_2", "sc1_4", "sc2_2", "sc2_4", "SCO5", "SCO11", "End2"))

# entspricht:
# select(mydata, !c(all_of(c(int1_items, int2_items, sc1_items, sc2_items, sco_ability_items, sco_opinion_items, enjoyment_items, identification_items)), "sc1_2", "sc1_4", "sc2_2", "sc2_4", "SCO5", "SCO11", "End2"))

# Die pipe nutzt die Variable vor der pipe |> als erstes Argument für die Funktion nach der pipe |>
# Teilweise wird auch %>% als pipe verwendet
# Für unsere heutigen Bedürfnisse sind beide pipes äquivalent
# %>% kommt aus der tidyverse-Bibliothek (bzw. aus magrittr), |> aus base R (keine Bibliothek nötig)
```

## Daten aufbereiten

```{r}
# Unsere Daten sind nicht ganz konsistent benannt
# Alter und Geschlecht sind groß geschrieben und auf Deutsch

# So können wir die Spalte neu benennen 
mydata_scales <- mydata_scales |>
  rename(age = Alter, gender = Geschlecht)
```

# Deskriptive Statistik

## Deskriptive Statistik

```{r}
# Verschaffen wir uns mal einen Überblick
describe(mydata_scales)
```

## Deskriptive Statistik nach Gruppen

```{r}
# So können wir uns die deskriptiven Statistiken getrennt nach Gruppen ausgeben lassen
describeBy(mydata_scales ~ sozpos)
# Die Tilde zeigt uns an, dass es sich hier um eine Formel handelt
# Das ist eine von R häufig genutzte Art Zusammenhänge zwischen Variablen darzustellen
# Links von der Tilde (~) steht bzw. stehen die AV(s), rechts von der Tilde die UV(s) 
# In diesem Fall sind alle Spalten die AV und die Spalte sozpos ist die UV
```

## Deskriptive Statistik nach Gruppen

```{r}
# Alternativ könnten wir das auch so schreiben:
describeBy(mydata_scales, group = mydata_scales[,"sozpos"])
```

# Zusammenhangsanalysen

## Korrelationen

```{r}
# Korrelationsvariablen festlegen
cor_vars <- c("sc1_mean", "sc2_mean", "int1_mean", "int2_mean", "sco_ability_mean", "sco_opinion_mean", "enjoyment_mean", "identification_mean")

# Korrelationsparamater für diese Variablen berechnen
corr.test(mydata_scales[,cor_vars])
```

## Skalenkorrelationen nach Gruppen getrennt

```{r}
# Die corr.test()-Funktion hat keinen "eingebauten" Gruppenvergleich
# Verschiedene andere Funktionen können diese Lücke aber schließen
# Mit der subset()-Funktion kann ich einen Teil der Fälle ausschließen
corr.test(subset(mydata_scales, sozpos == "low social position")[,cor_vars])
```

## Skalenkorrelationen nach Gruppen getrennt

```{r}
# Die filter()-Funktion wird etwas anders verwendet,
# das Ergebnis ist aber das gleiche wie bei der subset()-Funktion.
# Beide Funktionen stehen für zwei unterschiedliche Programmierlogiken,
# die in R parallel bestehen und je nach Anlass ausgewählt werden können.
mydata_scales |>
  filter(sozpos == "high social position") |>
  select(cor_vars) |>
  corr.test()
```

## Die (einfache) lineare Regression

```{r}
# Zusammenhänge können natürlich auch per Regressionsanalyse
# betrachtet werden. Hier wurde der Zusammenhang zwischen dem Selbstkonzept
# zum ersten und zweiten Messzeitpunkt mit der lm()-Funktion berechnet
lm(sc2_mean ~ sc1_mean, data = mydata_scales)
```

## Die (einfache) lineare Regression

```{r}
# Die summary()-Funktion liefert etwas ausführlichere Ergebnisse
summary(lm(sc2_mean ~ sc1_mean, data = mydata_scales))
```

## Die (einfache) lineare Regression

```{r}
# Man kann sich auch einzelne Elemente aus der Ausgabe anzeigen lassen
summary(lm(sc2_mean ~ sc1_mean, data = mydata_scales))[["coefficients"]]

# Das Intercept ist immer der vorhergesagte Wert für das Kriterium (hier sc2_mean)
# wenn alle Prädiktoren (hier sc1_mean) den Wert 0 haben. Jeder Erhöhung um einen Punkt
# in der Prädiktorvariable erhöht den vorhergesagten Wert für das Kriterium um das zugehörige
# b-Gewicht (Estimate)
# Das Modell sagt also aus:
# Eine Person mit einem Selbstkonzept von 0 im Pre-Test würde das Modell einen Post-Test Wert
# von (Intercept)
round(summary(lm(sc2_mean ~ sc1_mean, data = mydata_scales))[["coefficients"]][1,"Estimate"], 2)
# vorhersagen. Einer Person mit einem Pre-Test Selbstkonzept von 2 würde das Modell
# einen Post-Test Wert von (Intercept + 2 * Regressionsgewicht sc1_mean)
round(summary(lm(sc2_mean ~ sc1_mean, data = mydata_scales))[["coefficients"]][1,"Estimate"] + 2 * summary(lm(sc2_mean ~ sc1_mean, data = mydata_scales))[["coefficients"]][2,"Estimate"], 2)
# vorhersagen.
```

## Die (einfache) lineare Regression

```{r}
# Aus dem Regressionsmodell lässt sich auch die Korrelation ableiten.
# Zumindest im einfachsten Fall mit einem Kriterium und einem Prädiktor ist die 
# Korrelation r die Wurzel aus dem R²
sqrt(summary(lm(sc2_mean ~ sc1_mean, data = mydata_scales))[["r.squared"]])

# Zum Vergleich
corr.test(mydata_scales[,c("sc1_mean", "sc2_mean")])
```

# Einfache Gruppenvergleiche

## t-Test - Selbstkonzept

```{r}
# Wir könnten jetzt z.B. überprüfen, ob die vor der Intervention erhobenen Werte
# für Selbstkonzept und Interesse sich zwischen den Untersuchungsbedingungen unterscheiden

# Unterschiede in den Untersuchungsbedingungen im Selbstkonzept
# (Pre-Test)
t.test(sc1_mean ~ sozpos, data = mydata_scales)
```

## t-Test - Interesse

```{r}
# Unterschiede in den Untersuchungsbedingungen im Interesse
# (Pre-Test)
t.test(int1_mean ~ sozpos, data = mydata_scales)
```

## Regressionsbasierte Gruppenvergleiche

```{r}
# Das gleiche kann ich natürlich auch mit einer Regressionsanalyse berechnen
summary(lm(sc1_mean ~ sozpos, data = mydata_scales))

# Welche inhaltliche Bedeutung haben hier das Intercept und das Regressionsgewicht?
```

## Regressionsbasierte Gruppenvergleiche

```{r}
# Das war eine Analyse mit sogenanntem dummy-Kontrast
contrasts(mydata_scales[,"sozpos"])

# Bei dummy-Kontrasten ist eine Bedingung die Referenzbedingung (in diesem Fall low social position)
# Das Intercept ist im einfaktoriellen Fall der Mittelwert der Referenzbedingung
# Das Regressionsgewicht sozpos1 stellt den Unterschied zur anderen Bedingung dar
```

## Regressionsbasierte Gruppenvergleiche

```{r}
# Helmert-Kontraste wären eine andere Option
# Hier ist das Intercept der Mittelwert zwischen beiden Bedingungen
contrasts(mydata_scales[,"sozpos"]) <- c(-1,1)
summary(lm(sc1_mean ~ sozpos, data = mydata_scales))
# Mit den Kontrasten verändert sich auch die inhaltliche Interpretation
# der Regressionsgewichte. Hier steht das Regressionsgewicht für den
# Abstand jeder Gruppe vom Intercept (es ist also genau halb so groß
# wie im vorherigen Beispiel)
```

# Komplexere Gruppenvergleiche

## Multiple Regression

```{r}
# Fragestellung: Unterscheidet sich der Anstieg des Interesses von Pre-
# zu Post-Messung bei beiden Untersuchungsgruppen?
#
# Wie könnten wir vorgehen, um die Frage zu beantworten.
``` 

## Multiple Regression

```{r}
# Fragestellung: Unterscheidet sich der Anstieg des Interesses von Pre-
# zu Post-Messung bei beiden Untersuchungsgruppen?
#
# Wie könnten wir vorgehen, um die Frage zu beantworten.

# So sagen wir anhand der Gruppe den Wert zum Posttest vorher:
model1 <- lm(int2_mean ~ sozpos, data = mydata_scales)

# So sagen wir anhand der Gruppe den anhand des Wertes zum Prä-Test korrigierten
# Wert zum Posttest vorher:
model2 <- lm(int2_mean ~ sozpos + int1_mean, data = mydata_scales)

# Und so schauen wir noch, ob sich die Untersuchungsbedingung abhängig von der Höhe des
# Prä-Test Werts unterschiedlich auf die Entwicklung von Prä- zum Post-Test auswirkt:
model3 <- lm(int2_mean ~ sozpos + scale(int1_mean, scale = F) + sozpos:scale(int1_mean, scale = F), data = mydata_scales)
# 
``` 

## Multiple Regression

```{r}
summary(model1)
```

## Multiple Regression

```{r}
summary(model2)
```

## Multiple Regression

```{r}
summary(model3)
```

## Multiple Regression

```{r}
# Erklärt das jeweils komplexere Modell die Daten 
# wirklich besser als die jeweils einfacheren Modelle?
# Oder: Steigt das R-Quadrat signifikant an?
anova(model1, model2, model3)
```