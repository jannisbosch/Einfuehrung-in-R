---
title: "Datenanalyse in R I"
author: "Jannis Bosch"
format: 
  revealjs:
    theme: moon
execute:
  echo: true
embed-resources: true
---

## Setup

- Bitte erstellt wieder ein R Projekt und öffnet es

- Erstellt ein R-Skript für den heutigen Workshop

## Daten herunterladen

[Hier klicken um den Datensatz runterzuladen](dateien/experiment_data.rds){target="_blank"}

## Daten einlesen

```{r}
# Lest zunächst den Datensatz ein
mydata <- readRDS(file.path("dateien", "experiment_data.rds"))

# Schaut euch dann die Struktur des Datensatzes in RStudio an
```

# Wiederholung - Skalen bilden

## Items für die Skalen definieren

```{r}
# Im Datensatz sind Items aus acht verschiedenen Skalen
# Erstellt nun zunächst für jede Skala einen Vektor mit den Item-Namen im Datensatz
sc1_items <- c("sc1_1", "sc1_2_rev", "sc1_3", "sc1_4_rev") # self-concept (pre-test)
sc2_items <- c("sc2_1", "sc2_2_rev", "sc2_3", "sc2_4_rev") # self-concept (post-test)
int1_items <- c("int1_1", "int1_2", "int1_3", "int1_4") # interest (pre-test)
int2_items <- c("int2_1", "int2_2", "int2_3", "int2_4") # interest (post-test)
sco_ability_items <- c("SCO1", "SCO2", "SCO3", "SCO4", "SCO5_rev", "SCO6") # social comparison orientation ability
sco_opinion_items <- c("SCO7", "SCO8", "SCO9", "SCO10", "SCO11_rev") # social comparison orientation opinion
identification_items <- c("Ident1", "Ident2", "Ident3", "Ident4") # university identification
enjoyment_items <- c("End1", "End2_rev", "End3") # enjoyment of the task

# Diese Variablen können wir später zur Berechnung der Skalenmittelwerte nutzen
```

## Cronbach's Alpha

```{r}
# psych-Bibliothek laden
library(psych)

alpha(mydata[,sc1_items]) # entspricht: alpha(mydata[,c("sc1_1", "sc1_2_rev", "sc1_3", "sc1_4_rev")])

# Schaut euch mal das Cronbach's Alpha der SCO Skalen an
# Findet ihr potentiell unpassende Items?
```

## Cronbach's Alpha - SCO ability

```{r}
alpha(mydata[,sco_ability_items])
# Item 1 passt nicht perfekt
```

## Cronbach's Alpha - SCO ability
```{r}
alpha(mydata[,sco_opinion_items])
# Item 11 passt überhaupt nicht (Alpha geht hoch, Trennschärfe von .07)
```

## Skalenmittelwerte berechnen

```{r}
# Wie beim letzten mal erstellen wir jetzt neue Spalten für die 
# Skalenmittelwerte mit der rowMeans()-Funktion
mydata[,"sc1_mean"] <- rowMeans(mydata[,sc1_items], na.rm = T)
mydata[,"sc2_mean"] <- rowMeans(mydata[,sc2_items], na.rm = T)
mydata[,"int1_mean"] <- rowMeans(mydata[,int1_items], na.rm = T)
mydata[,"int2_mean"] <- rowMeans(mydata[,int2_items], na.rm = T)
mydata[,"sco_ability_mean"] <- rowMeans(mydata[,sco_ability_items], na.rm = T)
mydata[,"sco_opinion_mean"] <- rowMeans(mydata[,sco_opinion_items], na.rm = T)
mydata[,"identification_mean"] <- rowMeans(mydata[,identification_items], na.rm = T)
mydata[,"enjoyment_mean"] <- rowMeans(mydata[,enjoyment_items], na.rm = T)
```

# Exkurs: dplyr, tidyr und das tidyverse

## Das tidyverse

- Das tidyverse ist eine Sammlung von Bibliotheken zur Datenanalyse

- Es beinhaltet verschiedene Bibliotheken und Funktionen, die die Datenaufbereitung erleichtern, Tools zur Erstellung von Graphiken (ggplot) und vieles mehr

- Mehr Informationen unter <https://www.tidyverse.org/>

## R Cheat Sheets

- Cheat Sheets sind eine graphische Aufbereitung verschiedener Funktionen von Bibliotheken

- [dplyr Cheat Sheet](https://nyu-cdsc.github.io/learningr/assets/data-transformation.pdf){target="_blank"}

- [tidyr Cheat Sheet](https://raw.githubusercontent.com/rstudio/cheatsheets/main/tidyr.pdf){target="_blank"}

## tidyverse installieren

</br>
```{r}
#| eval: false
# Die Bibliothek installieren
install.packages("tidyverse")
```
</br>
```{r}
# Und die Bibliothek laden
library(tidyverse)
```

# Daten aufbereiten

## Datensatz aufräumen

```{r}
# Zur besseren Übersicht bietet es sich nach Berechnung der Skalenmittelwerte 
# an einen neuen Datensatz zu erstellen, der die Einzelitems nicht beinhaltet 
mydata_scales <- select(mydata, !c(all_of(c(int1_items, int2_items, sc1_items, sc2_items, sco_ability_items, sco_opinion_items, enjoyment_items, identification_items)), "sc1_2", "sc1_4", "sc2_2", "sc2_4", "SCO5", "SCO11", "End2"))
```

## Datensatz aufräumen

```{r}
# Das geht auch mit der pipe
mydata_scales <- mydata |>
  select(!c(all_of(c(int1_items, int2_items, sc1_items, sc2_items, sco_ability_items, sco_opinion_items, enjoyment_items, identification_items)), "sc1_2", "sc1_4", "sc2_2", "sc2_4", "SCO5", "SCO11", "End2"))

# entspricht:
# select(mydata, !c(all_of(c(int1_items, int2_items, sc1_items, sc2_items, sco_ability_items, sco_opinion_items, enjoyment_items, identification_items)), "sc1_2", "sc1_4", "sc2_2", "sc2_4", "SCO5", "SCO11", "End2"))

# Die pipe nutzt die Variable vor der pipe |> als erstes Argument für die Funktion nach der pipe |>
# Teilweise wird auch %>% als pipe verwendet
# Für unsere heutigen Bedürfnisse sind beide pipes äquivalent
# %>% kommt aus der tidyverse-Bibliothek (bzw. aus magrittr), |> aus base R (keine Bibliothek nötig)
```

## Daten aufbereiten

```{r}
# Unsere Daten sind nicht ganz konsistent benannt
# Alter und Geschlecht sind groß geschrieben und auf Deutsch

# So können wir die Spalte neu benennen 
mydata_scales <- mydata_scales |>
  rename(age = Alter, gender = Geschlecht)
```

# Deskriptive Statistik

## Deskriptive Statistik

```{r}
# Verschaffen wir uns mal einen Überblick
describe(mydata_scales)
```

## Deskriptive Statistik nach Gruppen

```{r}
# So können wir uns die deskriptiven Statistiken getrennt nach Gruppen ausgeben lassen
describeBy(mydata_scales ~ sozpos)
# Die Tilde zeigt uns an, dass es sich hier um eine Formel handelt
# Das ist eine von R häufig genutzte Art Zusammenhänge zwischen Variablen darzustellen
# Links von der Tilde (~) steht bzw. stehen die AV(s), rechts von der Tilde die UV(s) 
# In diesem Fall sind alle Spalten die AV und die Spalte sozpos ist die UV
```

## Deskriptive Statistik nach Gruppen

```{r}
# Alternativ könnten wir das auch so schreiben:
describeBy(mydata_scales, group = mydata_scales[,"sozpos"])
```

# Zusammenhangsanalysen

## Korrelationen

```{r}
# Korrelationsvariablen festlegen
cor_vars <- c("sc1_mean", "sc2_mean", "int1_mean", "int2_mean", "sco_ability_mean", "sco_opinion_mean", "enjoyment_mean", "identification_mean")

# Korrelationsparamater für diese Variablen berechnen
corr.test(mydata_scales[,cor_vars])
```

## Skalenkorrelationen nach Gruppen getrennt

```{r}
# Die corr.test()-Funktion hat keinen "eingebauten" Gruppenvergleich
# Verschiedene andere Funktionen können diese Lücke aber schließen
# Mit der subset()-Funktion kann ich einen Teil der Fälle ausschließen
corr.test(subset(mydata_scales, sozpos == "low social position")[,cor_vars])
```

## Skalenkorrelationen nach Gruppen getrennt

```{r}
# Die filter()-Funktion wird etwas anders verwendet,
# das Ergebnis ist aber das gleiche wie bei der subset()-Funktion.
# Beide Funktionen stehen für zwei unterschiedliche Programmierlogiken,
# die in R parallel bestehen und je nach Anlass ausgewählt werden können.
mydata_scales |>
  filter(sozpos == "high social position") |>
  select(cor_vars) |>
  corr.test()
```

## Die (einfache) lineare Regression

```{r}
# Zusammenhänge können natürlich auch per Regressionsanalyse
# betrachtet werden. Hier wurde der Zusammenhang zwischen dem Selbstkonzept
# zum ersten und zweiten Messzeitpunkt mit der lm()-Funktion berechnet
lm(sc2_mean ~ sc1_mean, data = mydata_scales)
```

## Die (einfache) lineare Regression

```{r}
# Die summary()-Funktion liefert etwas ausführlichere Ergebnisse
summary(lm(sc2_mean ~ sc1_mean, data = mydata_scales))
# Interpretation:
# Intercept - Wenn alle Prädiktoren einen Wert von 0 haben (in diesem
# Fall also wenn sc1_mean 0 ist), erwarten wir einen Wert von 0.319 
# für das Kriterium (sc2_mean)
```

## Die (einfache) lineare Regression

```{r}
# Man kann sich auch einzelne Elemente aus der Ausgabe anzeigen lassen
summary(lm(sc2_mean ~ sc1_mean, data = mydata_scales))[["coefficients"]]

# Das Intercept ist immer der vorhergesagte Wert für das Kriterium (hier sc2_mean)
# wenn alle Prädiktoren (hier sc1_mean) den Wert 0 haben. Jeder Erhöhung um einen Punkt
# in der Prädiktorvariable erhöht den vorhergesagten Wert für das Kriterium um das zugehörige
# b-Gewicht (Estimate)
# Das Modell sagt also aus:
# Eine Person mit einem Selbstkonzept von 0 im Pre-Test würde das Modell einen Post-Test Wert
# von (Intercept)
round(summary(lm(sc2_mean ~ sc1_mean, data = mydata_scales))[["coefficients"]][1,"Estimate"], 2)
# vorhersagen. Einer Person mit einem Pre-Test Selbstkonzept von 2 würde das Modell
# einen Post-Test Wert von (Intercept + 2 * Regressionsgewicht sc1_mean)
round(summary(lm(sc2_mean ~ sc1_mean, data = mydata_scales))[["coefficients"]][1,"Estimate"] + 2 * summary(lm(sc2_mean ~ sc1_mean, data = mydata_scales))[["coefficients"]][2,"Estimate"], 2)
# vorhersagen.
```

## Die (einfache) lineare Regression

```{r}
# Grafisch sieht das dann so aus:
ggplot(mydata_scales, aes(x = sc1_mean, y = sc2_mean)) + 
  geom_point() +
  stat_smooth(method = "lm", col = "red") +
  xlim(0, 7) +
  ylim(0, 7)
```

## Die (einfache) lineare Regression

```{r}
# Aus dem Regressionsmodell lässt sich auch die Korrelation ableiten.
# Zumindest im einfachsten Fall mit einem Kriterium und einem Prädiktor ist die 
# Korrelation r die Wurzel aus dem R²
sqrt(summary(lm(sc2_mean ~ sc1_mean, data = mydata_scales))[["r.squared"]])

# Zum Vergleich
corr.test(mydata_scales[,c("sc1_mean", "sc2_mean")])
```

# Einfache Gruppenvergleiche

## t-Test - Selbstkonzept

```{r}
# Wir könnten jetzt z.B. überprüfen, ob die vor der Intervention erhobenen Werte
# für Selbstkonzept und Interesse sich zwischen den Untersuchungsbedingungen unterscheiden

# Unterschiede in den Untersuchungsbedingungen im Selbstkonzept
# (Pre-Test)
t.test(sc1_mean ~ sozpos, data = mydata_scales)
```

## t-Test - Interesse

```{r}
# Unterschiede in den Untersuchungsbedingungen im Interesse
# (Pre-Test)
t.test(int1_mean ~ sozpos, data = mydata_scales)
```

## Regressionsbasierte Gruppenvergleiche

```{r}
# Das gleiche kann ich natürlich auch mit einer Regressionsanalyse berechnen
summary(lm(sc1_mean ~ sozpos, data = mydata_scales))

# Welche inhaltliche Bedeutung haben hier das Intercept und das Regressionsgewicht?
```

## Regressionsbasierte Gruppenvergleiche

```{r}
# Das war eine Analyse mit sogenanntem dummy-Kontrast
contrasts(mydata_scales[,"sozpos"])

# Bei dummy-Kontrasten ist eine Bedingung die Referenzbedingung (in diesem Fall low social position)
# Das Intercept ist im einfaktoriellen Fall der Mittelwert der Referenzbedingung
# Das Regressionsgewicht sozpos1 stellt den Unterschied zur anderen Bedingung dar
```

## Regressionsbasierte Gruppenvergleiche

```{r}
# Helmert-Kontraste wären eine andere Option
# Hier ist das Intercept der Mittelwert zwischen beiden Bedingungen
contrasts(mydata_scales[,"sozpos"]) <- c(-1,1)
summary(lm(sc1_mean ~ sozpos, data = mydata_scales))
# Mit den Kontrasten verändert sich auch die inhaltliche Interpretation
# der Regressionsgewichte. Hier steht das Regressionsgewicht für den
# Abstand jeder Gruppe vom Intercept (es ist also genau halb so groß
# wie im vorherigen Beispiel)
```

## Regressionsbasierte Gruppenvergleiche

```{r}
# Zur Veranschaulichung der Kontraste
ggplot(mydata_scales, aes(x = as.numeric(sozpos)-1, y = sc1_mean)) + 
  geom_point() +
  stat_smooth(method = "lm", col = "red") +
  xlim(0, 1) +
  ylim(0, 7)
```

## Übungsaufgaben

```{r}
# Das ist euer Übungsdatensatz
PlantGrowth <- PlantGrowth
PlantGrowth

## Aufgabe 1:
# Erstellt eine Tabelle mit der Gruppenaufteilung
# Hint: table()
```

## Übungsaufgaben

```{r}

## Aufgabe 1:
# Erstellt eine Tabelle mit der Gruppenaufteilung
# Hint: table()

# Lösung:
table(PlantGrowth[,"group"])
```

## Übungsaufgaben

```{r}
## Aufgabe 2:
# Bestimmt das Durchschnittsgewicht der Gesamtgruppe und
# der drei Untersuchungsgruppen.
# Hint: describeBy() oder komplizierter: subset()/filter() und mean()/describe()
```

## Übungsaufgaben

```{r}

## Aufgabe 2:
# Bestimmt das Durchschnittsgewicht der Gesamtgruppe und
# der drei Untersuchungsgruppen.

# Lösung describeBy():
describeBy(PlantGrowth ~ group)
describeBy(weight ~ group, data = PlantGrowth)
```

## Übungsaufgaben

```{r}
## Aufgabe 2:
# Bestimmt das Durchschnittsgewicht der Gesamtgruppe und
# der drei Untersuchungsgruppen.

# Lösung subset() und mean:
mean(subset(PlantGrowth, group == "ctrl")[,"weight"])
mean(subset(PlantGrowth, group == "trt1")[,"weight"])
mean(subset(PlantGrowth, group == "trt2")[,"weight"])
```

## Übungsaufgaben

```{r}

## Aufgabe 2:
# Bestimmt das Durchschnittsgewicht der Gesamtgruppe und
# der drei Untersuchungsgruppen.

# Lösung im dplyr-Stil:
PlantGrowth |>
  group_by(group) |>
  summarize(
    mean_weight = mean(weight)
  )
```

## Übungsaufgaben

```{r}
## Aufgabe 3:
# Berechnet eine Regressionsanalyse mit weight als Kriterium und
# group als Gruppenvariable
# Hint: lm() und summary()
# Was könnt ihr anhand der Regressionsgewichte und 
# der Ergebnisse aus Aufgabe 2 über die Kontraste sagen?
```

## Übungsaufgaben

```{r}

## Aufgabe 3:
# Berechnet eine Regressionsanalyse mit weight als Kriterium und
# group als Gruppenvariable
# Was könnt ihr anhand der Regressionsgewichte und 
# der Ergebnisse aus Aufgabe 2 über die Kontraste sagen?
# Lösung:
summary(lm(weight ~ group, data = PlantGrowth))
```

# Komplexere Gruppenvergleiche

## Multiple Regression

```{r}
# Fragestellung: Unterscheidet sich der Anstieg des Interesses von Pre-
# zu Post-Messung bei beiden Untersuchungsgruppen?
#
# Wie könnten wir vorgehen, um die Frage zu beantworten?
``` 

## Multiple Regression

```{r}
# Fragestellung: Unterscheidet sich der Anstieg des Interesses von Pre-
# zu Post-Messung bei beiden Untersuchungsgruppen?
#
# Wie könnten wir vorgehen, um die Frage zu beantworten?

# Nullmodell zum Vergleich
model0 <- lm(int2_mean ~ 1, data = mydata_scales)

# So sagen wir anhand der Gruppe den Wert zum Posttest vorher:
model1 <- lm(int2_mean ~ sozpos, data = mydata_scales)

# So sagen wir anhand der Gruppe den anhand des Wertes zum Prä-Test 
# korrigierten Wert zum Posttest vorher:
model2 <- lm(int2_mean ~ sozpos + int1_mean, data = mydata_scales)

# Und so schauen wir noch, ob sich die Untersuchungsbedingung abhängig von der Höhe des
# Prä-Test Werts unterschiedlich auf die Entwicklung von Prä- zum Post-Test auswirkt:
model3 <- lm(int2_mean ~ sozpos + int1_mean + sozpos:int1_mean, data = mydata_scales)

# Disclaimer: Man kann so vorgehen, besser wäre aber bei ausreichender Stichprobengröße
# ein Mehrebenen-Modell! Dieses Beispiel ist nur zur Veranschaulichung.
``` 

## Multiple Regression

```{r}
summary(model0)
```

## Multiple Regression

```{r}
summary(model1)
```

## Multiple Regression

```{r}
summary(model2)
```

## Multiple Regression

```{r}
summary(model3)
```

## Multiple Regression

```{r}
# Erklärt das jeweils komplexere Modell die Daten 
# wirklich besser als die jeweils einfacheren Modelle?
# Oder: Steigt das R-Quadrat signifikant an?
anova(model0, model1, model2, model3)

# Der p-Wert für den Modelltest mit dem lm()-Befehl entspricht
# jeweils dem Vergleich mit dem Nullmodell.
```

## Übungsaufgabe

- Führt die eben gezeigten Analysen mit dem Selbstkonzept durch und interpretiert die Ergebnisse

## Lösung

- Auf der nächsten Folie kommt die Lösung :)

## Lösung

```{r}
# Nullmodell:
model0sc <- lm(sc2_mean ~ 1, data = mydata_scales)

# Hier werden wieder die Post-Test Werte anhand der Gruppe
# vorhergesagt:
model1sc <- lm(sc2_mean ~ sozpos, data = mydata_scales)
# oder: model1sc <- update(model0sc, .~. + sozpos) 

# Hier wird wieder für die Prä-Test Werte korrigiert:
model2sc <- lm(sc2_mean ~ sozpos + sc1_mean, data = mydata_scales)
# oder: model2sc <- update(model1sc, .~. + sc1_mean)

# Und hier betrachten wir wieder, ob das ursprüngliche 
# Selbstkonzept den Effekt der Untersuchungsbedingung 
# beeinflusst:
model3sc <- lm(sc2_mean ~ sozpos + sc1_mean + sozpos:sc1_mean, data = mydata_scales)
# oder: model3sc <- update(model2sc, .~. + sc1_mean:sozpos)
# oder: model3sc <- lm(sc2_mean ~ sozpos*sc1_mean, data = mydata_scales)
```

## Lösung - Modell 0

```{r}
summary(model0sc)
```


## Lösung - Modell 1

```{r}
summary(model1sc)
```

## Lösung - Modell 2

```{r}
summary(model2sc)
```

## Lösung - Modell 3

```{r}
summary(model3sc)
```

## Lösung - Modellvergleiche

```{r}
anova(model0sc, model1sc, model2sc, model3sc)
```

## Noch eine Übungsaufgabe

- Dieses Mal nur mit metrischen Variablen

```{r}
#| eval: false
# installiert dafür die datarium-Bibliothek für den Datensatz
install.packages("datarium")
```

```{r}
# und ladet den Datensatz
data("marketing", package = "datarium")
# Ihr solltet jetzt die Variable marketing im Arbeitsspeicher sehen
```

## Noch eine Übungsaufgabe

```{r}
# Zunächst inspizieren wir den Datensatz
library(psych)
describe(marketing)

# Sales ist unsere AV und zeigen die Verkaufszahlen 
# der jeweiligen Firma (Einheit unbekannt)
# Die anderen drei Variablen (YT, FB, NP) sind unsere UVs
# und zeigen die Werbungskosten (in 1000€) auf der 
# jeweiligen Plattform
```

## Übungsaufgabe 1

Betrachtet die drei Plattformen zunächst einzeln und beantwortet die folgenden Fragestellungen:

- Gibt es einen Zusammenhang zwischen den über Facebook/Youtube/Zeitungen ausgegebenen Werbegeldern und den Verkaufszahlen?

## Lösung 1-1

```{r}
modelFB <- lm(sales ~ facebook, data = marketing)
summary(modelFB)

# Interpretation: Eine Firma, die kein Geld auf Facebook ausgibt, 
# hat einen erwarteten Verkaufswert von ca. 11 Einheiten.
# Mit jedem Anstieg um 1000€ steigt auch der erwartete 
# Verkaufswert um ca. 0.2 Einheiten.
# Aber: Keine Kausalinterpretation zulässig (es sei denn es würde # sich um ein Experiment handeln).
```

## Lösung 1-2

```{r}
modelYT <- lm(sales ~ youtube, data = marketing)
summary(modelYT)

# Interpretation: Eine Firma, die kein Geld auf Youtube ausgibt, 
# hat einen erwarteten Verkaufswert von ca. 8.4 Einheiten.
# Mit jedem Anstieg um 1000€ steigt auch der erwartete 
# Verkaufswert um ca. 0.05 Einheiten.
```

## Lösung 1-3

```{r}
modelNP <- lm(sales ~ newspaper, data = marketing)
summary(modelNP)

# Interpretation: Eine Firma, die kein Geld bei Zeitungen ausgibt,
# hat einen erwarteten Verkaufswert von ca. 14.8 Einheiten.
# Mit jedem Anstieg um 1000€ steigt auch der erwartete 
# Verkaufswert um ca. 0.05 Einheiten.
```

# Übungsaufgabe 2

- Betrachtet nun die Werbekosten auf Facebook und Youtube gemeinsam

- Beantwortet die Frage, ob die Daten für Synergie-Effekte sprechen (i.e., ob eine Investition auf FB und YT zusätzliche positive Effekte über die einzelnen Investitionen hinaus hat.)

# Lösung 2

